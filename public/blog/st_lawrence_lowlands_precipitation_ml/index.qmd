---
title: 'St. Lawrence Lowlands Precipitation Data: 30-Year Trends Prediction'
author: Johanie Fournier, agr., M.Sc.
date: "2025-01-28"
slug: st_lawrence_lowlands_precipitation_ML
categories:
  - rstats
  - tidymodels
  - tidytuesday
  - models
  - viz
tags:
  - rstats
  - tidymodels
  - tidytuesday
  - models
  - viz
summary: "In this phase of the analysis, we aim to model precipitation patterns in the St. Lawrence Lowlands using machine learning techniques, leveraging historical climate and environmental data. We will compare Random Forest, XGBoost, and Mars models to assess their ability to capture complex relationships and predict precipitation trends. Model performance will be evaluated using cross-validation and regression metrics to determine the most effective approach."
editor_options: 
  chunk_output_type: inline
adsense:
  publisher-id: ca-pub-7674504334497845
filters:
- adsense
resources:
 - ads.txt
---

```{r setup}
#| include: false
library(knitr)
knitr::opts_chunk$set(cache = TRUE, cache.lazy = FALSE, warning = FALSE, 
                      message = FALSE, echo = TRUE, dpi = 180,
                      fig.width = 7, fig.height = 5)

# Importer des données
library(openxlsx)

# explorer et présenter les données
library(inspectdf)
library(kableExtra)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(skimr)

# Parallel Processing
library(doFuture)

# Core 
library(recipes)
library(tidymodels)
library(timetk)
library(fs)

#Time series
library(modeltime)

#Import data
library(pins)

#H2O
#library(h2o)

#Geospatial
library(sf)
library(terra)

#Monitorer le temps que ça prend
library(tictoc)

#Tidytuesday
library(tidytuesdayR)

#Python
library(reticulate)
#renv::use_python()
Sys.setenv(RETICULATE_PYTHON = "~/Library/Mobile Documents/com~apple~CloudDocs/ADV/johaniefournier.com/renv/python/virtualenvs/renv-python-3.9/bin/python")
#py_install("pandas")
#py_install("requests")
#py_install("chardet")



#Mes fonctions
#devtools::install_github("jofou/jofou.lib")
library(jofou.lib)

#Theme_map
theme_map <- function(base_size=9, base_family="") { # 3
	require(grid)
	theme_bw(base_size=base_size, base_family=base_family) %+replace%
		theme(axis.line=element_blank(),
			  axis.text=element_blank(),
			  axis.ticks=element_blank(),
			  axis.title=element_blank(),
			  panel.background=element_blank(),
			  panel.border=element_blank(),
			  panel.grid=element_blank(),
			  panel.spacing=unit(0, "lines"),
			  plot.background=element_blank(),
			  legend.justification = c(0,0),
			  legend.position = c(0,0),
			  plot.title= element_text(size=20, hjust=0, color="black", face="bold"),
		)
}

#Graph theme
theme_set(theme_minimal() +
          theme(axis.line = element_line(linetype="solid", linewidth=.3, color="black"),
                axis.ticks = element_line(linetype="solid", linewidth=.5, color="black"),
                panel.grid.major.y = element_blank(),
                panel.grid.major.x = element_blank(),
                panel.grid.minor = element_blank(),
                axis.title.x = element_text(hjust = 0, face = "bold"),
                axis.title.y = element_text(hjust = 1, face = "bold"),
                title = element_text(hjust = 1, face = "bold", size=14)))

update_geom_defaults("rect", list(fill = "#DBBDC3", alpha = 0.8))
update_geom_defaults("line", list(fill = "#DBBDC3", alpha = 0.8))
update_geom_defaults("point", list(fill = "#DBBDC3", alpha = 0.8))

#CRS
#Geographic
#WGS84:"EPSG:4326"
#Projected
#NAD83:"EPSG3978"
```


[![Subscribe button](petit.png)](https://subscribepage.io/E3ia1B)

<br>

Understanding precipitation patterns in the St. Lawrence Lowlands is essential for climate analysis, agriculture, and water resource management. In the previous blog post, we conducted an exploratory data analysis (EDA) to uncover key trends, spatial distributions, and relationships within the dataset. This provided valuable insights into precipitation variability and guided feature selection for modeling.

Building on that foundation, this post explores machine learning approaches to predict precipitation using historical climate data. We will evaluate three models —Random Forest (RF), XGBoost, and and Mars- to determine their effectiveness in capturing complex climate patterns. Using cross-validation and standard regression metrics, we will compare model performance and identify the most suitable approach for precipitation prediction in this region.



## Data Preprocessing

The first step here is to load the data and preprocess it for modeling. We will extract relevant features and create a spatial weights matrix.

### Load the data

```{r}
precipitation_data <- readRDS("Data/precipitation_dt.rds") |> 
  select(shapeName, date, mean)
head(precipitation_data)
```

### Create a Spatial Weights Matrix


We need some spatial information extracted from the coordinate to put into the temporal model. We will use the GPS coordinates to create a k-nearest neighbors spatial weights matrix. This matrix will be used as spatial information of the observed emissions, which will be used as a predictor in the machine learning models. 

```{r}
qc_sf <- rgeoboundaries::gb_adm2(country = "CAN") |>
  filter(shapeName %in% c("Bas-Saint-Laurent", 
                          "Gaspésie--Îles-de-la-Madelei", 
                          "Capitale-Nationale",
                          "Chaudière-Appalaches",
                          "Estrie",
                          "Centre-du-Québec",
                          "Montérégie",
                          "Montréal",
                          "Laval",
                          "Outaouais",
                          "Abitibi-Témiscamingue",
                          "Lanaudière",
                          "Laurentides",
                          "Mauricie")) |> 
  select(shapeName, geometry) |> 
  st_centroid()
```


```{r}
precipitation_mrc_data<-precipitation_data |> 
  left_join(qc_sf, by = c("shapeName")) |>
  mutate(lon = st_coordinates(geometry)[,1],
         lat = st_coordinates(geometry)[,2],
         date=as.Date(date)) |> 
  as.data.frame() |> 
  select(-geometry)
```

```{r}
# Extract coordinates
coords <- precipitation_mrc_data |> 
  select(lon, lat)

# Create k-nearest neighbors spatial weights matrix (example with k = 4)
knn <- spdep::knearneigh(coords, k = 4, longlat = TRUE)
nb <- spdep::knn2nb(knn)
listw_knn <- spdep::nb2listw(nb, style = "W")

# Compute spatial lag using the weights matrix
spatial_lag <- spdep::lag.listw(listw_knn, precipitation_mrc_data$mean)

# Add the spatial lag
data_spatial <- precipitation_mrc_data |> 
  mutate(spatial_lag = spatial_lag) |> 
  select(-lon, -lat)
```

```{r}
top6_entity<-data_spatial |>
  select(shapeName) |>
  unique() |> 
  top_n(6) 

data_spatial |> 
    group_by(shapeName) |> 
    filter(shapeName %in% top6_entity$shapeName) |> 
    plot_time_series(date, mean,
                     .facet_ncol = 2,
                     .smooth = FALSE, 
                     .interactive = FALSE)
```


## Modeling

Now that we have the spatial information, we can start training machine learning models to predict future emissions. We will use the `modeltime` package to train and evaluate the models.

### Extend, Nesting and Splitting Data

First, we need to extend the time series data to include future observations for the next 20 years, then nest the data by the parent entity, and finally split the data into training and testing sets.

```{r}
nested_data_tbl <- data_spatial|> 
    group_by(shapeName)|> 
  #Extend
    extend_timeseries(
        .id_var = shapeName,
        .date_var = date,
        .length_future = 60 #predict 5 years
    )|> 
  #Nest
    nest_timeseries(
        .id_var = shapeName,
        .length_future = 60
    )|> 
  #Split
    split_nested_timeseries(
        .length_test = 60
    )
```


### Model Training

Next, we will train machine learning models to predict future emissions. We will train three models -Random Forest, XGBoost, and ARIMA- and evaluate their performance using the root mean square error (RMSE) metric. 

```{r}
# Recipe
rec <- recipe(mean ~ ., extract_nested_train_split(nested_data_tbl)) |> 
    step_timeseries_signature(date) |> 
    step_rm(date) |> 
    step_zv(all_predictors()) |> 
    step_dummy(all_nominal_predictors(), one_hot = TRUE)

# Models 
wflw_rf <- workflow()|> 
    add_model(rand_forest("regression", mtry=25, trees = 1000, min_n=25) |>  set_engine("randomForest")) |>  
              add_recipe(rec)

wflw_xgb <- workflow()|> 
    add_model(boost_tree("regression", learn_rate = 0.5) |>  set_engine("xgboost"))|> 
    add_recipe(rec)

wflw_mars <- workflow()|> 
    add_model(mars("regression", num_terms = 10) |>  set_engine("earth", endspan=200)) |>
    add_recipe(rec)

# Nested Modeling
parallel_start(6)
nested_modeltime_tbl <- nested_data_tbl|> 
    modeltime_nested_fit(
        model_list = list(
            wflw_rf,
            wflw_xgb,
            wflw_mars
        ),
        control = control_nested_fit(
            verbose   = TRUE,
            allow_par = TRUE
        )
    )
```

### Review Errors

Before selecting the best model, we need to review any errors that occurred during the training process. We will also check the accuracy of the models and investigate any anomalies.

```{r}
#| eval: FALSE
# #1) list errors
errors<-nested_modeltime_tbl|>
  extract_nested_error_report() #install all missing packages

#2) Spot too high accuracy
nested_modeltime_tbl |>
    extract_nested_test_accuracy() |>
    table_modeltime_accuracy()

#3) Investigate
nested_modeltime_tbl|>
    filter(shapeName == "Abitibi-Témiscamingue") |>
    extract_nested_train_split()
```


```{r}
nested_modeltime_tbl|>
    extract_nested_test_forecast() |>
    filter(shapeName == "Abitibi-Témiscamingue") |>
    group_by(shapeName) |>
    plot_modeltime_forecast(.facet_ncol = 3,
                            .interactive = FALSE) 
```

### Select Best Models

Next, we will select the best models based on the root mean square error (RMSE) metric. We will visualize the best models to compare their performance and identify any anomalies.

```{r}
nested_best_tbl <- nested_modeltime_tbl|> 
    modeltime_nested_select_best(metric = "rsq")

nested_best_tbl |> 
    extract_nested_test_forecast() |>
    filter(shapeName %in% top6_entity$shapeName) |> 
    group_by(shapeName) |> 
    plot_modeltime_forecast(.facet_ncol = 2, 
                            .legend_show = FALSE,
                            .interactive = FALSE)
```

### Refit Models

Finally, we will refit the best models on the entire dataset to make predictions for future emissions. We will also review any errors that occurred during the refitting process and visualize the future forecasts for the selected companies.

```{r}
# Refit
nested_best_refit_tbl <- nested_best_tbl|> 
    modeltime_nested_refit(
        control = control_refit(
            verbose   = TRUE,
            allow_par = TRUE
        )
    )

# Error last check
nested_best_refit_tbl|>  extract_nested_error_report()

# Visualize Future Forecast 
nested_best_refit_tbl|> 
    extract_nested_future_forecast() |> 
    filter(shapeName %in% top6_entity$shapeName) |> 
    group_by(shapeName) |> 
    plot_modeltime_forecast(.facet_ncol = 2, 
                            .legend_show = FALSE,
                            .interactive = FALSE)
```

### Save Preds

Finally, we will save the predictions for future emissions to a file for further analysis and visualization.

```{r, eval=FALSE}
nested_best_refit_tbl |> 
    extract_nested_future_forecast() |> 
    write_rds("Data/data_with_pred.rds")
```

## Animated visual

We can create an animated visualization of the future emissions predictions to better understand the trends and anomalies in the data.

### Load the Predicted Data

```{r}
library(ggthemes)
library(gganimate)

# load the predicted data
precipitation_dt<-readRDS("Data/data_with_pred.rds") |> 
  rename(date=.index, 
         mean=.value) |> 
  mutate(date=as.Date(date),
         year=year(date),
         month=month(date),
         month_name_abb = month(date, label = TRUE)) |> 
  select(shapeName, date, mean, year, month, month_name_abb)
```

### Estimating Anomalies

```{r}
# estimating anomalies
ref <- precipitation_dt |>
  group_by(shapeName, month) |>
  summarise(ref = mean(mean))

monthly_anomalies <- precipitation_dt |> 
  left_join(ref, by = c("shapeName", "month")) |> 
  mutate(anomalie = (mean * 100 / ref) - 100,
  sign = ifelse(anomalie > 0, "pos", "neg") |> factor(c("pos", "neg")),
  date=as.Date(date),
  month_name_abb = month(date, label = TRUE))
```

### Statistical Metrics

```{r}
data_norm <- group_by(monthly_anomalies, month_name_abb) |>
                summarise(
                  mx = max(anomalie),
                  min = min(anomalie),
                  q25 = stats::quantile(anomalie, .25),
                  q75 = stats::quantile(anomalie, .75),
                  iqr = q75 - q25
                )
DT::datatable(data_norm) |> 
  DT::formatRound(c("mx","min","q25","q75","iqr"), digits=1)
```

```{r}
#| eval: FALSE
library(ggthemes)
library(gganimate)

gg <- ggplot(data_norm) +
  geom_crossbar(aes(x = month_name_abb, 
                    y = 0, 
                    ymin = min, 
                    ymax = mx),
    fatten = 0, fill = "grey90", colour = "NA") + 
  geom_crossbar(aes(x = month_name_abb, 
                    y = 0, 
                    ymin = q25, 
                    ymax = q75),
  fatten = 0, fill = "grey70")  +
  geom_crossbar(
  data = filter(monthly_anomalies, shapeName=="Chaudière-Appalaches"),
  aes(x = month_name_abb, 
      y = 0, 
      ymin = 0, 
      ymax = anomalie, 
      group= year,
      fill = sign),
  fatten = 0, width = 0.7, alpha = .7, colour = "NA",
  show.legend = FALSE) + 
  transition_time(as.integer(year)) +
  ggtitle('Precipitation anomaly in Chaudière-Appalaches {frame_time}') +
  shadow_mark(past=FALSE) +
  geom_hline(yintercept = 0) +
  scale_fill_manual(values = c("#99000d", "#034e7b")) +
  scale_y_continuous("Precipitation anomaly (%)",
    breaks = seq(-5, 5, 1)
  ) +
  labs(
    x = "",
    caption = "Data: AgERA5"
  ) +
  theme_hc()
num_years <- max(monthly_anomalies$year) - min(monthly_anomalies$year) + 1

# Save the animation as a GIF
gganimate::animate(gg, duration = 30, fps = 4, width = 500, height = 300, renderer = gifski_renderer())
anim_save("gif/output.gif")
```

```{r}
# Read and display the saved GIF animation
animation <- magick::image_read("gif/output.gif")
print(animation, info = FALSE)
```

# Conclusion

In this analysis, we explored machine learning approaches to predict future emissions in the St. Lawrence Lowlands. We trained three models -Random Forest, XGBoost, and ARIMA- and evaluated their performance using the root mean square error (RMSE) metric. The Random Forest model outperformed the other models, capturing complex climate patterns and providing accurate predictions for future emissions. This model can be used to guide climate analysis, agriculture, and water resource management in the region.


# Sign up for the newsletter

[![Sign up](sign_up.png)](https://dashboard.mailerlite.com/forms/1478852/152663752035010469/share)
<br>

# Session Info

```{r}
sessionInfo()
```

