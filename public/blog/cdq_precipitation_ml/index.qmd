---
title: 'From Trends to Predictions: Machine Learning Forecasts for Centre-du-Québec’s Precipitation'
author: Johanie Fournier, agr., M.Sc.
date: "2025-01-30"
slug: cdq_precipitation_ML
categories:
  - rstats
  - tidymodels
  - models
  - viz
tags:
  - rstats
  - tidymodels
  - models
  - viz
summary: "In this phase of the analysis, we aim to model precipitation patterns in Centre-du-Québec using machine learning techniques, leveraging historical climate and environmental data. We will train an XGBoost models and predict precipitation trends. Model performance will be evaluated using cross-validation and regression metrics to determine the most effective approach."
editor_options: 
  chunk_output_type: inline
adsense:
  publisher-id: ca-pub-7674504334497845
filters:
- adsense
resources:
 - ads.txt
---

```{r setup}
#| include: false
library(knitr)
knitr::opts_chunk$set(cache = TRUE, cache.lazy = FALSE, warning = FALSE, 
                      message = FALSE, echo = TRUE, dpi = 180,
                      fig.width = 7, fig.height = 5)

# Importer des données
library(openxlsx)

# explorer et présenter les données
library(inspectdf)
library(kableExtra)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(skimr)

# Parallel Processing
library(doFuture)

# Core 
library(recipes)
library(tidymodels)
library(timetk)
library(fs)

#Time series
library(modeltime)

#Import data
library(pins)

#H2O
#library(h2o)

#Geospatial
library(sf)
library(terra)

#Monitorer le temps que ça prend
library(tictoc)

#Tidytuesday
library(tidytuesdayR)

#Python
library(reticulate)
#renv::use_python()
Sys.setenv(RETICULATE_PYTHON = "~/Library/Mobile Documents/com~apple~CloudDocs/ADV/johaniefournier.com/renv/python/virtualenvs/renv-python-3.9/bin/python")
#py_install("pandas")
#py_install("requests")
#py_install("chardet")



#Mes fonctions
#devtools::install_github("jofou/jofou.lib")
library(jofou.lib)

#Theme_map
theme_map <- function(base_size=9, base_family="") { # 3
	require(grid)
	theme_bw(base_size=base_size, base_family=base_family) %+replace%
		theme(axis.line=element_blank(),
			  axis.text=element_blank(),
			  axis.ticks=element_blank(),
			  axis.title=element_blank(),
			  panel.background=element_blank(),
			  panel.border=element_blank(),
			  panel.grid=element_blank(),
			  panel.spacing=unit(0, "lines"),
			  plot.background=element_blank(),
			  legend.justification = c(0,0),
			  legend.position = c(0,0),
			  plot.title= element_text(size=20, hjust=0, color="black", face="bold"),
		)
}

#Graph theme
theme_set(theme_minimal() +
          theme(axis.line = element_line(linetype="solid", linewidth=.3, color="black"),
                axis.ticks = element_line(linetype="solid", linewidth=.5, color="black"),
                panel.grid.major.y = element_blank(),
                panel.grid.major.x = element_blank(),
                panel.grid.minor = element_blank(),
                axis.title.x = element_text(hjust = 0, face = "bold"),
                axis.title.y = element_text(hjust = 1, face = "bold"),
                title = element_text(hjust = 1, face = "bold", size=14)))

update_geom_defaults("rect", list(fill = "#DBBDC3", alpha = 0.8))
update_geom_defaults("line", list(fill = "#DBBDC3", alpha = 0.8))
update_geom_defaults("point", list(fill = "#DBBDC3", alpha = 0.8))

#CRS
#Geographic
#WGS84:"EPSG:4326"
#Projected
#NAD83:"EPSG3978"
```



[![Subscribe button](petit.png)](https://subscribepage.io/E3ia1B)

<br>

Understanding precipitation patterns is essential for climate analysis, agriculture, and water resource management. In the previous blog post, we conducted an exploratory data analysis (EDA) to uncover key trends, spatial distributions, and relationships within the dataset. This provided valuable insights into precipitation variability and guided feature selection for modeling.

Building on that foundation, this post explores machine learning approaches to predict precipitation using historical climate data. We will train an XGBoost model and evaluate his effectiveness in capturing complex climate patterns. Using cross-validation and standard regression metrics, we will compare model performance and identify the most suitable approach for precipitation prediction in this region.



## Data Preprocessing

The first step here is to load the data and preprocess it for modeling. We will extract relevant features and create a spatial weights matrix.

### Load the data

```{r}
precipitation_data <- readRDS("Data/precipitation_sf.rds") |> 
  select(year, value) |> 
  filter(year>=1993 & year<=2023)
  
head(precipitation_data)
```

### Aggregate the Data

For this analysis, I need the sum for each year at every point. 

```{r}
precipitation_data_agg <- precipitation_data |>
  mutate(lon = st_coordinates(precipitation_data)[,1],
         lat = st_coordinates(precipitation_data)[,2]) |> 
  group_by(year, lon, lat) |>
  mutate(pts_id=row_number()) |> 
  summarise(value = sum(value))
```


### Create a Distance Matrix

```{r}
#| echo: false
blogdown::shortcode("youtube", "UH8RSlgiz9E")
```

We need some spatial information extracted from the coordinate to put into the temporal model. For this purpose, we will create a distance matrix using the `sf` package. 


```{r}
#| eval: FALSE
#Change for projected CRS
precipitation_data_proj<-precipitation_data_agg %>%
  sf::st_as_sf(.)%>% 
  st_transform(., 3978) 


#Create a distance matrix
buffer.dist<-precipitation_data_proj|> 
  filter(year==2023) |> 
  sf::st_distance(which="Euclidean") |> 
  as.data.frame() |> 
  mutate_all(as.numeric) 

buff.dist_all_years<-do.call("rbind", replicate(31, buffer.dist, simplify = FALSE))

#grouper les données avec la matrice de distance
data<-precipitation_data_proj %>%
  as.data.frame() %>% 
  bind_cols(buff.dist_all_years)%>% 
  na.omit() |> 
  select(-geometry)
```

```{r}
#| eval: FALSE
#| echo: FALSE

# save data
write_rds(data, "Data/data_spatial.rds")
```


## Modeling

Now that we have the spatial information, we can start training machine learning models to predict future emissions. 

### Splitting Data

```{r}
#| eval: FALSE
#Train/test
set.seed(123)
data_split <- initial_split(data)
data_train <- training(data_split)
data_test <- testing(data_split)
```


### Model Training

Next, we will train machine learning models to predict future emissions. We will train an  XGBoost model evaluate his performance using the root mean square error (RMSE) metric.


```{r}
#| eval: FALSE
# Model
spec <-boost_tree(mtry = tune(), min_n = tune(), trees = 1000) |> 
  set_mode("regression") |> 
  set_engine("xgboost")

#Grid
grid <- grid_space_filling(
  min_n(),
  finalize(mtry(), data_train),
  size = 10
)

#recipe
recipe<-recipe(as.formula(value ~.), data=data_train) |> 
    step_normalize(all_numeric_predictors())               

#Workflow
wf <- workflow() |> 
  add_recipe(recipe) |> 
  add_model(spec)

#Cross-validation 
data_folds <- vfold_cv(data_train)

res <- tune_grid(
  wf,
  resamples = data_folds,
  grid = grid,
  control = control_grid(save_pred = TRUE)
)
```

### Select Best Models

Next, we will select the best models based on the root mean square error (RMSE) metric. We will visualize the best models to compare their performance and identify any anomalies.

```{r}
#| eval: FALSE
#best model
best_auc <- select_best(res, metric="rmse")
```

### Finalize Workflow

Finally, we will finalize the workflow and fit the best model to the training data. We will then use the model to predict future emissions in the test set and save the predictions for further analysis.

```{r}
#| eval: FALSE
#Finalize worlfkow
final_xgb <- finalize_workflow(
  wf,
  best_auc
)

#Fit
fit_xgb <- final_xgb |> 
  fit(data_train)
```

### Evaluate Model Performance

Predicting the test data and evaluating the model performance using the RMSE metric.

```{r}
#| eval: FALSE
#Predict test set
y_pred <-fit_xgb |> 
predict(new_data=data_test)
```


```{r}
#| eval: FALSE
#| echo: FALSE

# save data
write_rds(y_pred, "Data/y_pred.rds")
write_rds(data_test, "Data/data_test.rds")
```

```{r}
#| echo: FALSE

# read data
y_pred<-readRDS("Data/y_pred.rds")
data_test<-readRDS("Data/data_test.rds")
```


```{r}
data_test_pred<-data_test |> 
  bind_cols(y_pred) |> 
  mutate(value=value*1000, 
         .pred=.pred*1000) |>
  mutate(residuals=value-.pred,
         sd=sd(value),
         sd_pred=sqrt((value-.pred)^2),
         sd_estimate=sqrt(sd^2+sd_pred^2),
         PI_05=.pred-1.645*sd_estimate,
         PI_95=.pred+1.645*sd_estimate,
         PE=(value-.pred)/value,
         APE=abs(PE),
         PE_sup=.pred+APE,
         PE_inf=.pred-APE)
```

#### RSQ

```{r}
rsq<-data_test_pred |>  
  rsq(truth=value, estimate=.pred)
DT::datatable(rsq) |> 
  DT::formatRound(c(".estimate"), digits=2)
```

#### RMSE

```{r}
rmse<-sqrt(mean(data_test_pred$residuals^2)) |> 
  as.data.frame() |> 
  rename(.estimate="sqrt(mean(data_test_pred$residuals^2))")
DT::datatable(rmse)|> 
  DT::formatRound(c(".estimate"), digits=2)
```

#### MAPE

```{r}
mape<-rmse/(mean(data_test_pred$value))*100 |> 
  as.data.frame()
DT::datatable(mape)|> 
  DT::formatRound(c(".estimate"), digits=2)
```

#### Visualize the Predictions

```{r}
gg <- ggplot(data=as.data.frame(data_test_pred), aes(y=.pred, x=value))
gg <- gg + geom_point(size=1, alpha=0.2)
gg <- gg + geom_smooth(method = "lm", SE= FALSE , color="red")
gg <- gg + geom_smooth(aes(x=value, y=PI_05), linetype="dashed")
gg <- gg + geom_smooth(aes(x=value, y=PI_95), linetype="dashed")
gg <- gg + geom_smooth(aes(x=value, y=PE_sup), linetype="dashed")
gg <- gg + geom_smooth(aes(x=value, y=PE_inf), linetype="dashed")
gg <- gg + geom_hline(yintercept = 50, linetype="dashed")
gg <- gg + geom_vline(xintercept = 50, linetype="dashed")
gg <- gg + theme_serif()
gg <- gg + labs(title ="Comparing Predict to Actual Values of Precipitations (1993-2023)",
                y="Predicted Precipitation (mm)",
                x="Actual Precipitation (mm)")
print(gg)
```


#### Residuals

```{r}
gg <- as.data.frame(data_test_pred) |>  
ggplot(aes(x=.pred, y=residuals))
gg <- gg + geom_point(size=1, alpha=0.2)
gg <- gg + geom_smooth(method = "lm")
gg <- gg + theme_serif()
gg <- gg + labs(title = "Residuals\n")
print(gg) 
```


## Predict 2024 to 2030

```{r}
#| eval: FALSE
buff.dist_new_years<-do.call("rbind", replicate(7, buffer.dist, simplify = FALSE))

points<-data |> 
  select(lon, lat) |> 
  unique()

all_points<-do.call("rbind", replicate(7, points, simplify = FALSE))

data_futur <- data.frame(
  year=rep(c(2024,2025,2026, 2027, 2028, 2029, 2030),each=81), 
  value=NA)  |> 
  bind_cols(all_points) |>
  bind_cols(buff.dist_new_years)

#Predict test set
new_pred <-fit_xgb |> 
predict(new_data=data_futur)

data_futur_with_pred<-data_futur |> 
  bind_cols(new_pred) |> 
  select(year, .pred, lon, lat) |>
  rename(value=.pred)
```

```{r}
#| eval: FALSE
precipitation_data_futur<-data |> 
  select(year, value, lon, lat) |>
  bind_rows(data_futur_with_pred) |> 
  st_as_sf(coords = c("lon", "lat")) |>
  st_set_crs(4326)
```

Let's take a look at the predicted precipitation values for 2024 to 2030.

```{r}
#| echo: FALSE
precipitation_data_futur<-readRDS("Data/precipitation_data_futur.rds")
```


```{r}
valid<-precipitation_data_futur |> 
  as.data.frame() |> 
  select(year, value) |>
  mutate(value=value*1000) |>
  group_by(year) |>
  summarise(mean=mean(value), sd=sd(value)) |> 
  filter(year>=2020) 

DT::datatable(valid) |> 
  DT::formatRound(c("mean", "sd"), digits=2)
```

So, we can clearly see here that even if this model seems to have a good performance, the predictions over many years are not very good. This is a proof that this model need to improve his understanding of the concept of seasonality.

```{r}
#| eval: FALSE
#| echo: FALSE

# save data
write_rds(precipitation_data_futur, "Data/precipitation_data_futur.rds")
```


# Conclusion

In this analysis, we trained an XGBoost model to predict precipitation patterns in Centre-du-Québec using historical climate data. The model performed well, but can't really capture complex climate patterns. By evaluating the model's performance using cross-validation and regression metrics, we identified the most effective approach for precipitation prediction in this region.


# Sign up for the newsletter

[![Sign up](sign_up.png)](https://dashboard.mailerlite.com/forms/1478852/152663752035010469/share)

<br>

# Session Info

```{r}
sessionInfo()
```


