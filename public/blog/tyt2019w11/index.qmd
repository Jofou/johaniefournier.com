---
title: 'TyT2024W21 - Carbon Majors Emissions Data'
author: Johanie Fournier, agr.
date: '2024-06-04'
slug: TyT2019W11
categories:
  - rstats
  - tidymodels
  - tidytuesday
tags:
  - rstats
  - tidymodels
  - tidytuesday
summary: "This week we're exploring historical emissions data from Carbon Majors. They have complied a database of emissions data going back to 1854. I add the coordinates to see if their is a relationship between the emissions and the geographical position."
---

```{r setup}
#| include: false
library(knitr)
knitr::opts_chunk$set(cache = TRUE, cache.lazy = FALSE, warning = FALSE, 
                      message = FALSE, echo = TRUE, dpi = 180,
                      fig.width = 7, fig.height = 5)

# Importer des données
library(openxlsx)

# explorer et présenter les données
library(inspectdf)
library(kableExtra)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(skimr)

# Parallel Processing
library(doFuture)

# Core 
library(recipes)
library(tidymodels)
library(timetk)
library(fs)


#Import data
library(pins)

#H2O
#library(h2o)

#Geospatial
library(sf)
library(terra)

#Monitorer le temps que ça prend
library(tictoc)

#Tidytuesday
library(tidytuesdayR)

#Python
library(reticulate)
#renv::use_python()
Sys.setenv(RETICULATE_PYTHON = "~/Library/Mobile Documents/com~apple~CloudDocs/ADV/johaniefournier.com/renv/python/virtualenvs/renv-python-3.9/bin/python")

#Mes fonctions
#devtools::install_github("jofou/jofou.lib")
library(jofou.lib)

#Theme_map
theme_map <- function(base_size=9, base_family="") { # 3
	require(grid)
	theme_bw(base_size=base_size, base_family=base_family) %+replace%
		theme(axis.line=element_blank(),
			  axis.text=element_blank(),
			  axis.ticks=element_blank(),
			  axis.title=element_blank(),
			  panel.background=element_blank(),
			  panel.border=element_blank(),
			  panel.grid=element_blank(),
			  panel.spacing=unit(0, "lines"),
			  plot.background=element_blank(),
			  legend.justification = c(0,0),
			  legend.position = c(0,0),
			  plot.title= element_text(size=20, hjust=0, color="black", face="bold"),
		)
}

#Graph theme
theme_set(theme_minimal() +
          theme(axis.line = element_line(linetype="solid", size=.3, color="black"),
                axis.ticks = element_line(linetype="solid", size=.5, color="black"),
                panel.grid.major.y = element_blank(),
                panel.grid.major.x = element_blank(),
                panel.grid.minor = element_blank(),
                axis.title.x = element_text(hjust = 0, face = "bold"),
                axis.title.y = element_text(hjust = 1, face = "bold"),
                title = element_text(hjust = 1, face = "bold", size=14)))

#CRS
#Geographic
#WGS84:"EPSG:4326"
#Projected
#NAD83:"EPSG3978"
```

This is my latest contribution to the [`#TidyTuesday` dataset](https://github.com/rfordatascience/tidytuesday) project, featuring a recent dataset on carbon major emissions.

## Modeling Goal

Our modeling goal is to predict carbon emissions over time for each location.

## Explore data

Let's start by reading in the data:

```{r}
emissions <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-05-21/emissions.csv')
glimpse(emissions)
```

How does the distribution of the predicted variable look? 

```{r}
emissions %>% 
  select(total_emissions_MtCO2e) %>% 
  my_num_dist()
```

This is a good example of a positively skewed distribution. Normally, this would raise concerns, but we are working with a time series. So let's take a look at it from an other angle. 

Is there a general trend over time?

```{r}
year_trend<-emissions %>% 
  select(year, total_emissions_MtCO2e) %>% 
  group_by(year) %>% 
  summarise(MtCO2e=round(sum(total_emissions_MtCO2e), digits=2)) 

ggplot(data=year_trend, aes(x=year, y=MtCO2e))+ 
  geom_point()
```

There is a clear trend: carbon emissions increase over time. To predict this trend in the future, we need more data.

## Get More Data

### City and Country

```{r}
parent_entity<-emissions %>% 
  select(parent_entity) %>% 
  unique()
DT::datatable(parent_entity)
```

```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup
from geopy.geocoders import Nominatim

# Load the Excel file
data = r.parent_entity

# Initialize the geolocator
geolocator = Nominatim(user_agent="geoapiExercises")

# Function to get headquarters from Wikipedia
def get_headquarters(company):
    try:
        search_url = f"https://en.wikipedia.org/wiki/{company.replace(' ', '_')}"
        response = requests.get(search_url)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Find the infobox and extract the headquarters
        infobox = soup.find('table', {'class': 'infobox vcard'})
        if infobox:
            for row in infobox.find_all('tr'):
                header = row.find('th')
                if header and 'Headquarters' in header.text:
                    return row.find('td').text.strip()
        return 'Headquarters not found'
    except Exception as e:
        return str(e)

# Apply the functions to the dataframe
data['headquarters'] = data['parent_entity'].apply(get_headquarters)
data.head()
```


### GPS Coordinates

```{r}
library(reticulate)
#Get the Python object into R env
headquarters<-py$data

#Get GPS coordinate
geocoded_data<-ggmap::geocode(headquarters$headquarters)
head(geocoded_data)
```

Many coordinates are missing, but for the sake of this exercise, let's continue with the city where all the information is available.

Let's put it all together!

```{r}

```


Questions to answers...

(Code)

Conclusion from data

## Build a model

Goal for the model...

(code)

some figures to show the result and the model performances

This plot shows us that...
